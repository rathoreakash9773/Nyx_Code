{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381ec81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed URL: https://www.pond5.com/stock-images/photos/tag/computer/?pp=1\n",
      "Scraping page 1...\n",
      "Downloaded image: 157525847.jpeg\n",
      "Downloaded image: 150323500.jpeg\n",
      "Downloaded image: 101529771.jpeg\n",
      "Downloaded image: 154330880.jpeg\n",
      "Downloaded image: 31773263.jpeg\n",
      "Downloaded image: 11657580.jpeg\n",
      "Downloaded image: 11769410.jpeg\n",
      "Downloaded image: 243412296.jpeg\n",
      "Downloaded image: 92123587.jpeg\n",
      "Downloaded image: 21623256.jpeg\n",
      "Downloaded image: 165455012.jpeg\n",
      "Downloaded image: 234407882.jpeg\n",
      "Downloaded image: 234626620.jpeg\n",
      "Downloaded image: 244729366.jpeg\n",
      "Downloaded image: 13890725.jpeg\n",
      "Downloaded image: 244578422.jpeg\n",
      "Downloaded image: 172460373.jpeg\n",
      "Downloaded image: 21579524.jpeg\n",
      "Downloaded image: 222767744.jpeg\n",
      "Downloaded image: 148423436.jpeg\n",
      "Downloaded image: 170588220.jpeg\n",
      "Downloaded image: 21687884.jpeg\n",
      "Downloaded image: 152109357.jpeg\n",
      "Downloaded image: 153904454.jpeg\n",
      "Downloaded image: 24721437.jpeg\n",
      "Downloaded image: 90751127.jpeg\n",
      "Downloaded image: 11338243.jpeg\n",
      "Downloaded image: 143553779.jpeg\n",
      "Downloaded image: 21570655.jpeg\n",
      "Downloaded image: 150214412.jpeg\n",
      "Downloaded image: 252859839.jpeg\n",
      "Downloaded image: 21545846.jpeg\n",
      "Downloaded image: 21534897.jpeg\n",
      "Downloaded image: 21657868.jpeg\n",
      "Downloaded image: 21623277.jpeg\n",
      "Downloaded image: 32176030.jpeg\n",
      "Downloaded image: 21550900.jpeg\n",
      "Downloaded image: 21658296.jpeg\n",
      "Downloaded image: 21550949.jpeg\n",
      "Downloaded image: 10929559.jpeg\n",
      "Downloaded image: 147725737.jpeg\n",
      "Downloaded image: 202621831.jpeg\n",
      "Downloaded image: 11915557.jpeg\n",
      "Downloaded image: 21496929.jpeg\n",
      "Downloaded image: 21794797.jpeg\n",
      "Downloaded image: 21594590.jpeg\n",
      "Downloaded image: 21782012.jpeg\n",
      "Downloaded image: 21596629.jpeg\n",
      "Data extraction complete.\n",
      "URLs download complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "category = 'Computer'\n",
    "# Base directory path where you want to save everything\n",
    "base_directory = f\"D:\\\\NYX\\\\pond5\\\\{category}\"  # Update this to your desired path\n",
    "\n",
    "# Create directories if they don't exist\n",
    "image_directory = os.path.join(base_directory, 'images')\n",
    "os.makedirs(image_directory, exist_ok=True)\n",
    "\n",
    "csv_file_name = f'{category}_post_urls.csv'\n",
    "\n",
    "csv_directory = base_directory\n",
    "os.makedirs(csv_directory, exist_ok=True)\n",
    "\n",
    "# CSV file setup\n",
    "csv_file_name = os.path.join(csv_directory, csv_file_name)\n",
    "\n",
    "# Headers for the request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "# Function to fetch and process data from the webpage\n",
    "def fetch_data_from_page(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all a tags with class \"SearchResultDSM SearchResultDSM--large Link--dark p5_photo js-searchResult js-searchResultLarge js-awProductLink\"\n",
    "        a_tags = soup.find_all('a', class_='SearchResultDSM SearchResultDSM--large Link--dark p5_photo js-searchResult js-searchResultLarge js-awProductLink', href=True)\n",
    "\n",
    "        with open(csv_file_name, mode='a', newline='', encoding='utf-8') as file:  # Open file in append mode\n",
    "            writer = csv.writer(file)\n",
    "            if file.tell() == 0:  # Check if file is empty\n",
    "                writer.writerow(['ID', 'Image URL', 'Post URL', 'Title'])  # Write header only if file is empty\n",
    "\n",
    "            for a_tag in a_tags:\n",
    "                # Extract the post URL\n",
    "                post_url = a_tag['href']\n",
    "\n",
    "                # Extract the image URL from the img tag within the a tag\n",
    "                img_tag = a_tag.find('img', class_='SearchResultsV3-mosaicItemImg')\n",
    "                if img_tag:\n",
    "                    image_url = img_tag.get('src') or img_tag.get('data-src')\n",
    "                    title = img_tag['alt']\n",
    "                else:\n",
    "                    image_url = None\n",
    "                    title = None\n",
    "\n",
    "                # Extract the ID from the post URL\n",
    "                post_id = re.search(r'/item/(\\d+)-', post_url).group(1) if post_url else None\n",
    "\n",
    "                # Write ID, image URL, post URL, and title to CSV\n",
    "                writer.writerow([post_id, image_url, post_url, title])\n",
    "                #print(f\"ID: {post_id}, Image URL: {image_url}, Post URL: {post_url}, Title: {title}\")\n",
    "\n",
    "                # Download image\n",
    "                if image_url:\n",
    "                    image_response = requests.get(image_url)\n",
    "                    if image_response.status_code == 200:\n",
    "                        # Get the image file extension\n",
    "                        image_extension = image_url.split('.')[-1]\n",
    "\n",
    "                        # Save the image with the post ID as filename\n",
    "                        image_filename = f\"{post_id}.{image_extension}\"\n",
    "                        image_path = os.path.join(image_directory, image_filename)\n",
    "                        with open(image_path, 'wb') as image_file:\n",
    "                            image_file.write(image_response.content)\n",
    "                        print(f\"Downloaded image: {image_filename}\")\n",
    "                    else:\n",
    "                        print(f\"Failed to download image from URL: {image_url}\")\n",
    "                else:\n",
    "                    print(\"Image URL not found in the post.\")\n",
    "\n",
    "        print(\"Data extraction complete.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch page: {url}\")\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "base_url = \"https://www.pond5.com/stock-images/photos/tag/computer/\"\n",
    "num_pages = 1  # Number of pages to scrape\n",
    "\n",
    "# Iterate through each page\n",
    "for page_num in range(1, num_pages + 1):\n",
    "    page_url = f\"{base_url}?pp={page_num}\"\n",
    "    print(\"Constructed URL:\", page_url)\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    fetch_data_from_page(page_url)\n",
    "\n",
    "print(\"URLs download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742bc8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
