{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bced373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\akash rathore\\anaconda3\\lib\\site-packages (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5baf8ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download cntImg src. Error: Invalid URL 'cntImg src': No scheme supplied. Perhaps you meant https://cntImg src?\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\393772fb79b5edc084accd54b7729656_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\942e7b6791aad8ac8042ff30105a547f_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\a0d2b093109b6225a4f3c3d11f44a27e_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\9e2cacaa3eb1d44948a20705cd115539_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\a8ceed827f7f402713aef481cc5f7920_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\c1131a19f98853f516c3279429df1a4d_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\5aed194055a110e8eba215e557205d92_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\3aec8efaf39f91e6e2b743e2daec1440_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\942e7b6791aad8ac8042ff30105a547f_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\942e7b6791aad8ac8042ff30105a547f_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\a0d2b093109b6225a4f3c3d11f44a27e_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\a0d2b093109b6225a4f3c3d11f44a27e_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\9e2cacaa3eb1d44948a20705cd115539_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\9e2cacaa3eb1d44948a20705cd115539_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\c1131a19f98853f516c3279429df1a4d_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\c1131a19f98853f516c3279429df1a4d_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\5aed194055a110e8eba215e557205d92_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\5aed194055a110e8eba215e557205d92_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\393772fb79b5edc084accd54b7729656_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\393772fb79b5edc084accd54b7729656_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\a8ceed827f7f402713aef481cc5f7920_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\a8ceed827f7f402713aef481cc5f7920_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\3aec8efaf39f91e6e2b743e2daec1440_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\3aec8efaf39f91e6e2b743e2daec1440_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\c885f2cd88e845f72dadfb417d318d282fbe20a9_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\1e3159da86f6d9574c6bae6f4e35ef47_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\74d68a031995a85dbfdc54b977d487ed_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\c885f2cd88e845f72dadfb417d318d282fbe20a9_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\c885f2cd88e845f72dadfb417d318d282fbe20a9_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\23b73ecd4c56f9e614aa694a2b3e07ad_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\45e855c1444ce83d6423ec13b0049321_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\ad96860506afb9995cb3f368996a2b6d_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\360b88bdec1fefabd04428e79a44bdc1_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\1e3159da86f6d9574c6bae6f4e35ef47_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\1e3159da86f6d9574c6bae6f4e35ef47_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\74d68a031995a85dbfdc54b977d487ed_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\74d68a031995a85dbfdc54b977d487ed_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\45e855c1444ce83d6423ec13b0049321_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\45e855c1444ce83d6423ec13b0049321_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\9dc37fe9624bb3fd85042548079c53ee_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\360b88bdec1fefabd04428e79a44bdc1_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\360b88bdec1fefabd04428e79a44bdc1_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\ad96860506afb9995cb3f368996a2b6d_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\ad96860506afb9995cb3f368996a2b6d_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\23b73ecd4c56f9e614aa694a2b3e07ad_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\23b73ecd4c56f9e614aa694a2b3e07ad_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\9dc37fe9624bb3fd85042548079c53ee_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\9dc37fe9624bb3fd85042548079c53ee_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\859763bc9b056c872586a6c11f5a03d3_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\e584c893-9bc8-421b-8a83-ef3b406b5008_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\056a1aded04ef42c6558dc1c4581115c2649de19_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\56a6672aa3e31fb83e9cde023d8cc13d_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\f6acc6bfb0622d50e06643abac6828a3_low.webp\n",
      "Downloaded as .webp: D:\\Python\\NYX\\Insta_folders\\Output\\4\\3cf712a548fcb37f18e8bcae3b5ba169_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\e584c893-9bc8-421b-8a83-ef3b406b5008_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\e584c893-9bc8-421b-8a83-ef3b406b5008_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\859763bc9b056c872586a6c11f5a03d3_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\859763bc9b056c872586a6c11f5a03d3_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\56a6672aa3e31fb83e9cde023d8cc13d_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\56a6672aa3e31fb83e9cde023d8cc13d_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\3cf712a548fcb37f18e8bcae3b5ba169_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\3cf712a548fcb37f18e8bcae3b5ba169_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\f6acc6bfb0622d50e06643abac6828a3_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\f6acc6bfb0622d50e06643abac6828a3_low.webp\n",
      "Converted to .png: D:\\Python\\NYX\\Insta_folders\\Output\\4\\056a1aded04ef42c6558dc1c4581115c2649de19_low.png\n",
      "Deleted original .webp file: D:\\Python\\NYX\\Insta_folders\\Output\\4\\056a1aded04ef42c6558dc1c4581115c2649de19_low.webp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def download_image(url, destination_folder):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {url}. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extract the file name from the URL\n",
    "    file_name_webp = urlparse(url).path.split(\"/\")[-1]\n",
    "    file_path_webp = os.path.join(destination_folder, file_name_webp)\n",
    "\n",
    "    # Save the image as .webp to the destination folder\n",
    "    try:\n",
    "        with open(file_path_webp, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded as .webp: {file_path_webp}\")\n",
    "\n",
    "        # Convert to PNG\n",
    "        convert_to_png(file_path_webp, destination_folder)\n",
    "\n",
    "        # Delete the original WebP file\n",
    "        os.remove(file_path_webp)\n",
    "        print(f\"Deleted original .webp file: {file_path_webp}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error processing {url}. Error: {e}\")\n",
    "\n",
    "def convert_to_png(webp_path, destination_folder):\n",
    "    # Load the WebP image and save as PNG\n",
    "    try:\n",
    "        image = Image.open(webp_path)\n",
    "        png_path = os.path.splitext(webp_path)[0] + \".png\"\n",
    "        image.save(png_path, \"PNG\")\n",
    "        print(f\"Converted to .png: {png_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {webp_path} to PNG. Error: {e}\")\n",
    "\n",
    "def download_images_from_csv(csv_file, destination_folder):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        # Create the destination folder if it doesn't exist\n",
    "        os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "        # Use ThreadPoolExecutor for concurrent downloading and processing\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for row in reader:\n",
    "                if row:  # Check if the row is not empty\n",
    "                    image_url = row[0]  # Assuming the image URL is in the first column\n",
    "                    executor.submit(download_image, image_url, destination_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = r\"C:\\Users\\akash rathore\\Downloads\\seaart2.csv\"  # Replace with the path to your CSV file\n",
    "    output_folder = r\"D:\\Python\\NYX\\Insta_folders\\Output\\4\"  # Replace with your desired location\n",
    "\n",
    "    download_images_from_csv(csv_file_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# CSV file paths\n",
    "input_csv_filename = r\"C:\\Users\\akash rathore\\Downloads\\civitai.csv\"\n",
    "output_csv_filename = r\"C:\\Users\\akash rathore\\Downloads\\url2.csv\"   # empty csv\n",
    "\n",
    "# Check if the output file exists or create a new one with headers\n",
    "headers = [\"URL\", \"Name\", \"Prompts\", \"Date\", \"Comments\", \"Likes\", \"Hearts\"]\n",
    "\n",
    "try:\n",
    "    with open(output_csv_filename, mode='x', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "except FileExistsError:\n",
    "    pass  # File already exists\n",
    "\n",
    "# Read URLs from input CSV\n",
    "with open(input_csv_filename, mode='r', encoding='utf-8') as input_file:\n",
    "    csv_reader = csv.DictReader(input_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        url = row['url']\n",
    "        \n",
    "        # Open the URL\n",
    "        driver.get(url)\n",
    "\n",
    "        # Find and extract information\n",
    "        info = driver.find_element(By.CLASS_NAME, \"imgpage-info\")\n",
    "        name = info.find_element(By.XPATH, \"(//div[@class='name'])[1]\").find_element(By.TAG_NAME, \"a\").text\n",
    "        prompts = info.find_element(By.XPATH, \"(//div[@class='prompt'])[1]\").text\n",
    "        date = info.find_element(By.XPATH, \"(//span[@class='item'])[2]\").find_element(By.CLASS_NAME, \"value\").text\n",
    "        comments = info.find_element(By.XPATH, \"(//div[@class='commNum'])[1]\").text\n",
    "        likes = info.find_element(By.XPATH, \"(//div[@class='commFunNum'])[1]\").text\n",
    "        hearts = info.find_element(By.XPATH, \"(//div[@class='commFunNum el-popover__reference'])[1]\").text\n",
    "\n",
    "        # Append data to output CSV\n",
    "        with open(output_csv_filename, mode='a', newline='', encoding='utf-8') as output_file:\n",
    "            writer = csv.writer(output_file)\n",
    "            writer.writerow([url, name, prompts, date, comments, likes, hearts])\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df788a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import csv\n",
    "# import requests\n",
    "# from urllib.parse import urlparse\n",
    "# from PIL import Image\n",
    "\n",
    "# def download_image(url, destination_folder):\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Failed to download {url}. Error: {e}\")\n",
    "#         return\n",
    "\n",
    "#     # Extract the file name from the URL\n",
    "#     file_name_webp = urlparse(url).path.split(\"/\")[-1]\n",
    "#     file_path_webp = os.path.join(destination_folder, file_name_webp)\n",
    "\n",
    "#     # Save the image as .webp to the destination folder\n",
    "#     try:\n",
    "#         with open(file_path_webp, 'wb') as file:\n",
    "#             file.write(response.content)\n",
    "#         print(f\"Downloaded as .webp: {file_path_webp}\")\n",
    "\n",
    "#         # Convert to PNG\n",
    "#         convert_to_png(file_path_webp, destination_folder)\n",
    "\n",
    "#         # Delete the original WebP file\n",
    "#         os.remove(file_path_webp)\n",
    "#         print(f\"Deleted original .webp file: {file_path_webp}\")\n",
    "#     except IOError as e:\n",
    "#         print(f\"Error processing {url}. Error: {e}\")\n",
    "\n",
    "# def convert_to_png(webp_path, destination_folder):\n",
    "#     # Load the WebP image and save as PNG\n",
    "#     try:\n",
    "#         image = Image.open(webp_path)\n",
    "#         png_path = os.path.splitext(webp_path)[0] + \".png\"\n",
    "#         image.save(png_path, \"PNG\")\n",
    "#         print(f\"Converted to .png: {png_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error converting {webp_path} to PNG. Error: {e}\")\n",
    "\n",
    "# def download_images_from_csv(csv_file, destination_folder):\n",
    "#     with open(csv_file, 'r') as file:\n",
    "#         reader = csv.reader(file)\n",
    "\n",
    "#         # Create the destination folder if it doesn't exist\n",
    "#         os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "#         for row in reader:\n",
    "#             if row:  # Check if the row is not empty\n",
    "#                 image_url = row[0]  # Assuming the image URL is in the first column\n",
    "#                 download_image(image_url, destination_folder)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     csv_file_path = r\"C:\\Users\\akash rathore\\Downloads\\civitai2.csv\" # Replace with the path to your CSV file\n",
    "#     output_folder = r\"D:\\Python\\NYX\\Insta_folders\\Output\\2\"  # Replace with your desired location\n",
    "\n",
    "#     download_images_from_csv(csv_file_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9036a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # CSV file paths\n",
    "# input_csv_filename = r\"C:\\Users\\akash rathore\\Downloads\\seaart2.csv\"\n",
    "# output_csv_filename = r\"C:\\Users\\akash rathore\\Downloads\\New.csv\"\n",
    "\n",
    "# # Check if the output file exists or create a new one with headers\n",
    "# headers = [\"Name\", \"Prompts\", \"Date\"]\n",
    "\n",
    "# try:\n",
    "#     with open(output_csv_filename, mode='x', newline='', encoding='utf-8') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow(headers)\n",
    "# except FileExistsError:\n",
    "#     pass  # File already exists\n",
    "\n",
    "# # Read URLs from input CSV\n",
    "# with open(input_csv_filename, mode='r', encoding='utf-8') as input_file:\n",
    "#     csv_reader = csv.DictReader(input_file)\n",
    "\n",
    "#     for row in csv_reader:\n",
    "#         url = row['url']\n",
    "\n",
    "#         # Make a request to the URL and get the content\n",
    "#         response = requests.get(url)\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#         # Find and extract information using BeautifulSoup with error handling\n",
    "#         name_element = soup.select_one(\".name a\")\n",
    "#         prompts_element = soup.select_one(\".prompt\")\n",
    "#         date_element = soup.select_one(\".item:nth-of-type(2) .value\")\n",
    "#         comments_element = soup.select_one(\".commNum\")\n",
    "#         likes_element = soup.select_one(\".commFunNum\")\n",
    "#         hearts_element = soup.select_one(\".heartNum\")  # Adjust this selector\n",
    "\n",
    "#         # Check if elements are found before accessing the text attribute\n",
    "#         name = name_element.text.strip() if name_element else \"\"\n",
    "#         prompts = prompts_element.text.strip() if prompts_element else \"\"\n",
    "#         date = date_element.text.strip() if date_element else \"\"\n",
    "#         comments = comments_element.text.strip() if comments_element else \"\"\n",
    "#         likes = likes_element.text.strip() if likes_element else \"\"\n",
    "#         hearts = hearts_element.text.strip() if hearts_element else \"\"\n",
    "\n",
    "#         # Append data to output CSV\n",
    "#         with open(output_csv_filename, mode='a', newline='', encoding='utf-8') as output_file:\n",
    "#             writer = csv.writer(output_file)\n",
    "#             writer.writerow([name, prompts, date])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e8f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
