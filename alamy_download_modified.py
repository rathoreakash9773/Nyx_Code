# -*- coding: utf-8 -*-
"""alamy_download_modified.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ul9uy9NZnTwqe6wE-xspK2cJUuQ9_VI5
"""



import requests
import csv
import os
from PIL import Image
from io import BytesIO

zone = 'north west'
state = 'rajasthan'
city = 'jodhpur'
link = 'link4'
start_page = 1
end_page = 3

def fetch(end_page):
    # Base directory path where we want to save everything
    base_directory = r"/nyx_ai_data/ai_dev/{zone}/{state}/{city}/link1".format(zone=zone, state=state, city=city)
    image_folder_name = f'{link}_{city}_cropped_alamy_images'
    csv_file_name = f'{link}_{city}_alamy_data.csv'
    image_directory = os.path.join(base_directory, image_folder_name)
    csv_directory = base_directory
    os.makedirs(image_directory, exist_ok=True)
    os.makedirs(csv_directory, exist_ok=True)

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
    }

    # CSV file setup
    csv_file_path = os.path.join(csv_directory, csv_file_name)
    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        # Writing the headers
        writer.writerow(['URL', 'Caption', 'Upload Date', 'ID', 'Image Path'])

        image_count = 0  # To keep track of downloaded images
        for i in range(start_page, end_page):  # Assuming you might want to loop through pages
            url = f'https://www.alamy.com/search-api/search/?qt=jodhpur&ag=adult,baby,child,senior,teenager,toddler,youngAdult&hc=0,1,2,3,4,5%2B&sortBy=relevant&ispartial=true&langcode=en&isbot=false&type=picture&geo=IN&pn={i}&ps=100&nasty=0&editorial=1&rmuid=b1184d65-262e-4f3b-aa39-f4f7f4c8394d&translate=true&sessionid=b1184d65-262e-4f3b-aa39-f4f7f4c8394d'

            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                try:
                    data = response.json()
                    for post in data['items']:
                        # Ensure 'renditions' and 'zoom_large' keys exist
                        if 'renditions' in post and 'zoom_large' in post['renditions']:
                            image_response = requests.get(post['renditions']['zoom_large']['href'], headers=headers)
                            if image_response.status_code == 200:
                                # Open the image directly from the response content
                                image = Image.open(BytesIO(image_response.content))

                                # Process and save the image
                                image_path = os.path.join(image_directory, f"{post['altids']['seq']}_cropped.jpg")
                                strip_height = 30
                                cropped_img = crop_bottom_strip(image, strip_height)
                                cropped_img.save(image_path)
                                print(f"Cropped image saved to {image_path}")
                                image_count += 1
                                # Write to CSV
                                writer.writerow([
                                    post['renditions']['zoom_large']['href'],
                                    post.get('caption', 'No caption'),
                                    post['uploaddate'].split('T')[0],
                                    post['altids']['seq'],
                                    image_path
                                ])
                            else:
                                print(f"Failed to download image for post {post['id']}")
                        else:
                            print(f"Missing 'renditions' or 'zoom_large' key for post {post['id']}")
                except ValueError:
                    print("Response is not in JSON format")
            else:
                print(f"Failed to retrieve data for page {i}, status code:", response.status_code)

    # Print summary at the end
    print(f"Downloaded and cropped {image_count} images.")
    print(f"CSV created at: {csv_file_path}")

def crop_bottom_strip(img, strip_height):
    """
    Crops the bottom strip of an image.

    :param img: PIL Image object.
    :param strip_height: Height of the bottom strip to remove.
    :return: Cropped PIL Image object.
    """
    width, height = img.size
    # Define the coordinates of the top left and bottom right corners of the new image
    crop_box = (0, 0, width, height - strip_height)
    cropped_img = img.crop(crop_box)
    return cropped_img

# Call the fetch function
fetch(end_page)